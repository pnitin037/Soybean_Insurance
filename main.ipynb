{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdlib as imd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpdX\n",
    "import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "path = \"c:/Users/pniti/Downloads/python programming/Inrisk_lab_case_study\"\n",
    "\n",
    "start_yr = 2001\n",
    "end_yr = 2023\n",
    "variable = 'rain'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading the data\n",
    "# imd.get_data('rain',1980, end_yr, fn_format='yearwise', file_dir=path)\n",
    "# imd.get_data('tmin', start_yr, end_yr, fn_format='yearwise', file_dir=path)\n",
    "# imd.get_data('tmax', 1980, end_yr, fn_format='yearwise', file_dir=path)\n",
    "\n",
    "# Opening the data\n",
    "# data  = imd.open_data('rain', 1980, 2023,'yearwise', path)\n",
    "# data1 = imd.open_data('tmin', 2001, 2023,'yearwise', path)\n",
    "# data2 = imd.open_data('tmax', 1980, 2023,'yearwise', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving data as csv file\n",
    "\n",
    "# latLong = [[23.0783,75.4211],[23.0812,76.1904],[22.4252,76.2179],[22.3998,75.4489]]\n",
    "\n",
    "# for points in latLong:\n",
    "#     lat = points[0]\n",
    "#     lon = points[1]\n",
    "#     data.to_csv('IMD/data_rain.csv', lat, lon, path)\n",
    "#     data1.to_csv('IMD/data_tmin.csv', lat, lon, path)\n",
    "#     data2.to_csv('IMD/data_tmax.csv', lat, lon, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the IMD rainfall data\n",
    "p1 = pd.read_csv('IMD/data_rain_22.40_75.45.csv')\n",
    "p2 = pd.read_csv('IMD/data_rain_22.43_76.22.csv')\n",
    "p3 = pd.read_csv('IMD/data_rain_23.08_75.42.csv')\n",
    "p4 = pd.read_csv('IMD/data_rain_23.08_76.19.csv')\n",
    "\n",
    "\n",
    "p1['DateTime'] = pd.to_datetime(p1.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "p2['DateTime'] = pd.to_datetime(p2.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "p3['DateTime'] = pd.to_datetime(p3.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "p4['DateTime'] = pd.to_datetime(p4.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "\n",
    "p1 = pd.merge(p1,p2, on='DateTime', how='inner')\n",
    "p1 = pd.merge(p1,p3, on='DateTime', how='inner')\n",
    "p1 = pd.merge(p1,p4, on='DateTime', how='inner')\n",
    "\n",
    "p1 = p1[p1['DateTime'].dt.month.between(6,11)]\n",
    "p1.insert(5,'Rainfall_mean',p1.iloc[:,1:].mean(axis=1))\n",
    "p1 = p1.reset_index(drop=True)\n",
    "p1.to_csv('IMD/data_rain.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the IMD Min temperature data\n",
    "tmin1 = pd.read_csv('IMD/data_tmin_22.40_75.45.csv')\n",
    "tmin2 = pd.read_csv('IMD/data_tmin_22.43_76.22.csv')\n",
    "tmin3 = pd.read_csv('IMD/data_tmin_23.08_75.42.csv')\n",
    "tmin4 = pd.read_csv('IMD/data_tmin_23.08_76.19.csv')\n",
    "\n",
    "tmin1['DateTime'] = pd.to_datetime(tmin1.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "tmin2['DateTime'] = pd.to_datetime(tmin2.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "tmin3['DateTime'] = pd.to_datetime(tmin3.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "tmin4['DateTime'] = pd.to_datetime(tmin4.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "\n",
    "tmin1 = pd.merge(tmin1,tmin2, on='DateTime', how='inner')\n",
    "tmin1 = pd.merge(tmin1,tmin3, on='DateTime', how='inner')\n",
    "tmin1 = pd.merge(tmin1,tmin4, on='DateTime', how='inner')\n",
    "\n",
    "tmin1 = tmin1[tmin1['DateTime'].dt.month.between(6,11)]\n",
    "tmin1.insert(5,'tmin_mean',tmin1.iloc[:,1:].mean(axis=1))\n",
    "tmin1 = tmin1.reset_index(drop=True)\n",
    "tmin1.to_csv('IMD/data_tmin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the IMD Max temperature data\n",
    "tmax1 = pd.read_csv('IMD/data_tmax_22.40_75.45.csv')\n",
    "tmax2 = pd.read_csv('IMD/data_tmax_22.43_76.22.csv')\n",
    "tmax3 = pd.read_csv('IMD/data_tmax_23.08_75.42.csv')\n",
    "tmax4 = pd.read_csv('IMD/data_tmax_23.08_76.19.csv')\n",
    "\n",
    "tmax1['DateTime'] = pd.to_datetime(tmax1.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "tmax2['DateTime'] = pd.to_datetime(tmax2.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "tmax3['DateTime'] = pd.to_datetime(tmax3.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "tmax4['DateTime'] = pd.to_datetime(tmax4.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "\n",
    "tmax1 = pd.merge(tmax1,tmax2, on='DateTime', how='inner')\n",
    "tmax1 = pd.merge(tmax1,tmax3, on='DateTime', how='inner')\n",
    "tmax1 = pd.merge(tmax1,tmax4, on='DateTime', how='inner')\n",
    "\n",
    "tmax1 = tmax1[tmax1['DateTime'].dt.month.between(6,11)]\n",
    "tmax1.insert(5,'tmax_mean',tmax1.iloc[:,1:].mean(axis=1))\n",
    "tmax1 = tmax1.reset_index(drop=True)\n",
    "tmax1.to_csv('IMD/data_tmax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_water_l1 = pd.read_csv('era5/era5_daily_soil_water_l1.csv')\n",
    "soil_water_l1['Time'] = pd.to_datetime(soil_water_l1.iloc[:,0],format=\"%Y-%m-%d\")\n",
    "soil_water_l1 = soil_water_l1.rename(columns={'Time':'DateTime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax1 = pd.read_csv('IMD/data_tmax.csv')\n",
    "tmax1['DateTime'] = pd.to_datetime(tmax1.iloc[:,1],format=\"%Y-%m-%d\")\n",
    "tmax1 = tmax1.rename(columns={'DateTime':'DateTime'})\n",
    "t = tmax1.groupby(tmax1['DateTime'].dt.month)['tmax_mean'].sum().reset_index()\n",
    "t.iloc[0,1] = t.iloc[0,1]/(44*30)\n",
    "t.iloc[1,1] = t.iloc[1,1]/(44*31)\n",
    "t.iloc[2,1] = t.iloc[2,1]/(44*31)\n",
    "t.iloc[3,1] = t.iloc[3,1]/(44*30)\n",
    "t.iloc[4,1] = t.iloc[4,1]/(44*31)\n",
    "t.iloc[5,1] = t.iloc[5,1]/(44*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.read_csv('IMD/data_rain.csv')\n",
    "rain['DateTime'] = pd.to_datetime(rain.iloc[:, 1], format=\"%Y-%m-%d\")\n",
    "rainn = rain.groupby(rain['DateTime'].dt.month)['Rainfall_mean'].sum().reset_index()\n",
    "rainn.rename(columns={'Rainfall_mean': 'Avg_monthly_Rainfall'}, inplace=True)\n",
    "rain_month = rainn['Avg_monthly_Rainfall'] / 44\n",
    "\n",
    "rainn = rain.groupby(rain['DateTime'].dt.year)['Rainfall_mean'].sum().reset_index()\n",
    "rainn.rename(columns={'Rainfall_mean': 'Halfyearly_Rainfall'}, inplace=True)\n",
    "normal_rain = rainn['Halfyearly_Rainfall'].mean()  # average annual rainfall from 1980 to 2022\n",
    "thershold_rain = normal_rain * 1.2  # 20% more than average annual rainfall and also known as threshold for excess rainfall\n",
    "\n",
    "rainn = rainn[rainn['DateTime'].between(2001, 2022)]\n",
    "rainn.rename(columns={'DateTime': 'Year'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    123.576093\n",
       "1    286.033944\n",
       "2    284.064655\n",
       "3    164.642324\n",
       "4     33.480323\n",
       "5      7.087799\n",
       "Name: Avg_monthly_Rainfall, dtype: float64"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.read_csv('IMD/data_rain.csv')\n",
    "tmin = pd.read_csv('IMD/data_tmin.csv')\n",
    "tmax = pd.read_csv('IMD/data_tmax.csv')\n",
    "\n",
    "tmin['DateTime']=pd.to_datetime(tmin.iloc[:,1],format=\"%Y-%m-%d\")\n",
    "rain['DateTime']=pd.to_datetime(rain.iloc[:,1],format=\"%Y-%m-%d\")\n",
    "tmax['DateTime']=pd.to_datetime(tmax.iloc[:,1],format=\"%Y-%m-%d\")\n",
    "\n",
    "tmin.drop(columns=['22.3998 75.4489','22.4252 76.2179','23.0783 75.4211','23.0812 76.1904','Unnamed: 0'],axis=1,inplace=True)\n",
    "rain.drop(columns=['22.3998 75.4489','22.4252 76.2179','23.0783 75.4211','23.0812 76.1904','Unnamed: 0'],axis=1,inplace=True)\n",
    "tmax.drop(columns=['22.3998 75.4489','22.4252 76.2179','23.0783 75.4211','23.0812 76.1904','Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "weather = pd.merge(rain,tmax,how='inner',on='DateTime')\n",
    "weather = pd.merge(weather,tmin,how='inner',on='DateTime')\n",
    "weather = pd.merge(weather,soil_water_l1,how='inner',on='DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['moving_avg_rain'] = weather['Rainfall_mean'].rolling(window=3).mean()\n",
    "weather['moving_avg_tmax'] = weather['tmax_mean'].rolling(window=5).mean()\n",
    "weather['moving_avg_soil_water_l1'] = weather['Soil_water_l1'].rolling(window=3).mean()\n",
    "weather['moving_avg_rain'] = weather['moving_avg_rain'].fillna(0)\n",
    "weather['moving_avg_tmax'] = weather['moving_avg_tmax'].fillna(0)\n",
    "weather['moving_avg_soil_water_l1'] = weather['moving_avg_soil_water_l1'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Year'] = weather['DateTime'].dt.year\n",
    "weather['Month'] = weather['DateTime'].dt.month\n",
    "monthly_temp = weather.groupby(['Year', 'Month'])['tmax_mean'].mean().reset_index()\n",
    "monthly_temp.rename(columns={'tmax_mean': 'Monthly_Max_Temp'}, inplace=True)\n",
    "monthly_rainfall = weather.groupby(['Year', 'Month'])['Rainfall_mean'].sum().reset_index()\n",
    "monthly_rainfall.rename(columns={'Rainfall_mean': 'Monthly_Rainfall'}, inplace=True)\n",
    "weather = pd.merge(weather, rainn, on='Year', how='inner')\n",
    "weather = pd.merge(weather, monthly_temp, on=['Year', 'Month'], how='inner')\n",
    "weather = pd.merge(weather, monthly_rainfall, on=['Year', 'Month'], how='inner')\n",
    "weather['Excess_Rainfall'] = 0\n",
    "weather['Deficit_Rainfall'] = 0\n",
    "weather['Extream_Heat'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Triggers for perils\n",
    "# Excessive Rainfall \n",
    "weather.loc[(weather['DateTime'].dt.month == 6)  & (weather['Monthly_Rainfall'] > (rain_month.iloc[0] * 1.1)) & (weather['moving_avg_rain'] > 58) & (weather['moving_avg_soil_water_l1'] > 50), 'Excess_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 7)  & (weather['Monthly_Rainfall'] > (rain_month.iloc[1] * 1.1)) & (weather['moving_avg_rain'] > 58) & (weather['moving_avg_soil_water_l1'] > 50), 'Excess_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 8)  & (weather['Monthly_Rainfall'] > (rain_month.iloc[2] * 1.1)) & (weather['moving_avg_rain'] > 58) & (weather['moving_avg_soil_water_l1'] > 47), 'Excess_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 9)  & (weather['Monthly_Rainfall'] > (rain_month.iloc[3] * 1.1)) & (weather['moving_avg_rain'] > 58) & (weather['moving_avg_soil_water_l1'] > 50), 'Excess_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 10) & (weather['Monthly_Rainfall'] > (rain_month.iloc[4] * 1.1)) & (weather['moving_avg_rain'] > 58) & (weather['moving_avg_soil_water_l1'] > 50), 'Excess_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 11) & (weather['Monthly_Rainfall'] > (rain_month.iloc[5] * 1.1)) & (weather['moving_avg_rain'] > 58) & (weather['moving_avg_soil_water_l1'] > 50), 'Excess_Rainfall'] = 1\n",
    "\n",
    "# Extream Heat\n",
    "weather.loc[(weather['DateTime'].dt.month.between(6,9))   & (weather['Monthly_Max_Temp'] > 33) & (weather['moving_avg_tmax'] > 35) & (weather['moving_avg_soil_water_l1'] < 20), 'Extream_Heat'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month.between(10,11)) & (weather['Monthly_Max_Temp'] > 33) & (weather['moving_avg_tmax'] > 35) & (weather['moving_avg_soil_water_l1'] < 30), 'Extream_Heat'] = 1\n",
    "\n",
    "# Deficit Rainfall\n",
    "weather.loc[(weather['DateTime'].dt.month == 6)  & (weather['Monthly_Rainfall'] < (rain_month.iloc[0] * 0.9)) & (weather['Monthly_Max_Temp'] > 35) & (weather['moving_avg_soil_water_l1'] < 20), 'Deficit_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 7)  & (weather['Monthly_Rainfall'] < (rain_month.iloc[1] * 0.9)) & (weather['Monthly_Max_Temp'] > 35) & (weather['moving_avg_soil_water_l1'] < 20), 'Deficit_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 8)  & (weather['Monthly_Rainfall'] < (rain_month.iloc[2] * 0.9)) & (weather['Monthly_Max_Temp'] > 35) & (weather['moving_avg_soil_water_l1'] < 20), 'Deficit_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 9)  & (weather['Monthly_Rainfall'] < (rain_month.iloc[3] * 0.9)) & (weather['Monthly_Max_Temp'] > 35) & (weather['moving_avg_soil_water_l1'] < 20), 'Deficit_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 10) & (weather['Monthly_Rainfall'] < (rain_month.iloc[4] * 0.9)) & (weather['Monthly_Max_Temp'] > 35) & (weather['moving_avg_soil_water_l1'] < 30), 'Deficit_Rainfall'] = 1\n",
    "weather.loc[(weather['DateTime'].dt.month == 11) & (weather['Monthly_Rainfall'] < (rain_month.iloc[5] * 0.9)) & (weather['Monthly_Max_Temp'] > 35) & (weather['moving_avg_soil_water_l1'] < 30), 'Deficit_Rainfall'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weather.groupby(weather['DateTime'].dt.to_period('Y')).agg({\"Excess_Rainfall\" : lambda series: series.sum()})\n",
    "w = pd.merge(w,weather.groupby(weather['DateTime'].dt.to_period('Y')).agg({\"Deficit_Rainfall\" : lambda series: series.sum()}),how='inner',on='DateTime').reset_index()\n",
    "w = pd.merge(w,weather.groupby(weather['DateTime'].dt.to_period('Y')).agg({\"Extream_Heat\" : lambda series: series.sum()}),how='inner',on='DateTime').reset_index()\n",
    "w.drop(columns=['index'],axis=1,inplace=True)\n",
    "w = w[w['DateTime'] != pd.Period('2010')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultivation = pd.read_excel('soyabean cultivation data.xlsx')\n",
    "cultivation.rename(columns={'Unnamed: 4':'Production (Tonnes)','Soyabean':' Area (Hectare)','Unnamed: 5':'Yield (Tonne/Hectare)'},inplace=True)\n",
    "cultivation = cultivation.drop([0,1,2]).drop(columns=['State','District'],axis=1).reset_index(drop=True)\n",
    "\n",
    "w['Yield (Tonne/Hectare)'] = cultivation['Yield (Tonne/Hectare)'].astype(float)\n",
    "w['Yield (Tonne/Hectare)'] = w['Yield (Tonne/Hectare)'].astype(float)\n",
    "w = w[w['DateTime'].dt.year >= 2011].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency of risk events\n",
    "f1 = ((w['Excess_Rainfall'] > 0).sum())/len(w)\n",
    "f2 = ((w['Deficit_Rainfall'] >0).sum())/len(w)\n",
    "f3 = ((w['Extream_Heat'] > 0).sum())/len(w) # Extreme_heat.\n",
    "\n",
    "w['total_breaches'] = w['Excess_Rainfall'] + w['Deficit_Rainfall'] + w['Extream_Heat']\n",
    "# Calculate severity  baseline_yield\n",
    "baseline_yield = w['Yield (Tonne/Hectare)'].nlargest(4).mean() # Assume the year with highest yield as baseline (no loss) we trrying to get average yield of the soybean crop.\n",
    "w['Yield_Loss'] = (baseline_yield - w['Yield (Tonne/Hectare)'])/baseline_yield\n",
    "\n",
    "yield_loss_1 = (w[w['Excess_Rainfall'] > 0]['Yield_Loss']*(w['Excess_Rainfall']/w['total_breaches'])).mean()\n",
    "yield_loss_2 = (w[w['Deficit_Rainfall'] > 0]['Yield_Loss']*(w['Deficit_Rainfall']/w['total_breaches'])).mean()\n",
    "yield_loss_3 = (w[w['Extream_Heat'] > 0]['Yield_Loss']*(w['Extream_Heat']/w['total_breaches'])).mean()\n",
    "      # MSP of soyabean = 4890 per quintal and 1 tonne = 10 quintal this implies msp of soyabean = 48900 per tonne\n",
    "loss_severity_1 = yield_loss_1 * baseline_yield * 48900\n",
    "loss_severity_2 = yield_loss_2 * baseline_yield * 48900\n",
    "loss_severity_3 = yield_loss_3 * baseline_yield * 48900\n",
    "\n",
    "# Calculate economic loss\n",
    "expected_loss_1 = loss_severity_1 * f1\n",
    "expected_loss_2 = loss_severity_2 * f2\n",
    "expected_loss_3 = loss_severity_3 * f3\n",
    "\n",
    "expected_total_loss = expected_loss_1 + expected_loss_2 + expected_loss_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0998341625207297)"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average yield loss % per breach of excess rainfall trigger\n",
    "((w[w['Excess_Rainfall'] > 0]['Yield_Loss']*(w['Excess_Rainfall']/w['total_breaches'])).sum())/(sum(w['Excess_Rainfall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.00935573703808004)"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average yield loss % per breach of deficit rainfall trigger\n",
    "((w[w['Deficit_Rainfall'] > 0]['Yield_Loss']*(w['Deficit_Rainfall']/w['total_breaches'])).sum())/sum(w['Deficit_Rainfall'])# average yield loss % per breach of deficit rainfall trigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.01965866223726268)"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((w[w['Extream_Heat'] > 0]['Yield_Loss']*(w['Extream_Heat']/w['total_breaches'])).sum())/sum(w['Extream_Heat'])# average yield loss % per breach of extream heat trigger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
